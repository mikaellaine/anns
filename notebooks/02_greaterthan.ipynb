{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_function(features, labels, mode):\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 1])\n",
    "    hidden = tf.layers.dense(inputs=input_layer, units=1)\n",
    "    logits = tf.layers.dense(inputs=hidden, units=2)\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets define the training data. Remeber, numpy arrays are required for Tensorflow (and we've imported numpy as 'np')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_data   = np.asarray( [1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32 )\n",
    "    train_labels = np.asarray( [0, 0, 0, 0, 1, 1, 1, 1], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual data input object...\n",
    "<li>x: If we want to present more than one feature, we have to give a dict, hence the \"x\" (we could've named it anything we wanted)\n",
    "<li>y: labels tensor\n",
    "<li>batch size: how many features to present at once\n",
    "<li>num_epochs: how many times to present the complete data (or None, for no limit)\n",
    "<li>shuffle: to randomize the order of features or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=10,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to remove the model later (if you change the model or if you want to start training from the beginning), just remove the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"examplemodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the estimator object, by through which the model is used. Notice we also define a directory where the model will be saved during training. If we wish to run more iterations of training, the previous state of the model will be automatically loaded from that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=model_function, model_dir=\"examplemodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the estimator (often called a classifier, which it actually is in this case), we can call train on it. Lets do 100 training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train( input_fn=train_input_fn, steps=10000 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can present the estimator with an evaluation data set and see what the accuracy of the trained model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\":train_data},\n",
    "  y=train_labels,\n",
    "  num_epochs=1,\n",
    "  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = estimator.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is trained, lets use it. Type in a number below to find which class it belongs to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [6]\n",
    "test_data = np.asarray(test_data, dtype=np.float32)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn( x={\"x\":test_data}, num_epochs=1, shuffle=False )\n",
    "eval_results = estimator.predict(input_fn=eval_input_fn)\n",
    "print(list(eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [2]\n",
    "test_data = np.asarray(test_data, dtype=np.float32)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn( x={\"x\":test_data}, num_epochs=1, shuffle=False )\n",
    "eval_results = estimator.predict(input_fn=eval_input_fn)\n",
    "res = next(eval_results)\n",
    "print(\"The number \"+str(test_data[0])+\" is \"+(\"greater than 4\" if res[\"classes\"]==1 else \"less than 5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets look at the model's internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(estimator.get_variable_names()))\n",
    "print(\"WEIGHTS 0\"+str(estimator.get_variable_value(\"dense/kernel\")))\n",
    "print(\"BIAS 0\"+str(estimator.get_variable_value(\"dense/bias\")))\n",
    "print(\"WEIGHTS 1\"+str(estimator.get_variable_value(\"dense_1/kernel\")))\n",
    "print(\"BIAS 1\"+str(estimator.get_variable_value(\"dense_1/bias\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
